{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa7009df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 10), (1000, 10))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data loading\n",
    "import pandas as pd\n",
    "\n",
    "raw = pd.read_csv('data/raw_data.csv')\n",
    "inc = pd.read_csv('data/incremental_data.csv')\n",
    "\n",
    "raw.shape, inc.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e17abc",
   "metadata": {},
   "source": [
    "### Dataset Loading\n",
    "\n",
    "Both the **raw** and **incremental** CSV files were successfully loaded from the `/data` folder.\n",
    "\n",
    "- The raw dataset contains 8,000 records and 10 columns.  \n",
    "- The incremental dataset contains 1,000 records and the same structure.\n",
    "\n",
    "These files represent student performance data, generated synthetically for this ETL exercise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61329cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000 entries, 0 to 7999\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   student_id   8000 non-null   int64  \n",
      " 1   name         8000 non-null   object \n",
      " 2   gender       8000 non-null   object \n",
      " 3   age          8000 non-null   int64  \n",
      " 4   subject      8000 non-null   object \n",
      " 5   exam_score   8000 non-null   float64\n",
      " 6   exam_date    8000 non-null   object \n",
      " 7   region       8000 non-null   object \n",
      " 8   grade_level  8000 non-null   object \n",
      " 9   school       8000 non-null   object \n",
      "dtypes: float64(1), int64(2), object(7)\n",
      "memory usage: 625.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>age</th>\n",
       "      <th>exam_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8000.00000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5506.66650</td>\n",
       "      <td>21.484750</td>\n",
       "      <td>69.848670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2605.57068</td>\n",
       "      <td>2.294488</td>\n",
       "      <td>17.305507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1000.00000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>40.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3252.50000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>54.727500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5513.50000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>69.815000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7758.25000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>84.682500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9999.00000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       student_id          age   exam_score\n",
       "count  8000.00000  8000.000000  8000.000000\n",
       "mean   5506.66650    21.484750    69.848670\n",
       "std    2605.57068     2.294488    17.305507\n",
       "min    1000.00000    18.000000    40.010000\n",
       "25%    3252.50000    19.000000    54.727500\n",
       "50%    5513.50000    22.000000    69.815000\n",
       "75%    7758.25000    23.000000    84.682500\n",
       "max    9999.00000    25.000000   100.000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data inspection\n",
    "raw.head()\n",
    "raw.info()\n",
    "raw.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085ac078",
   "metadata": {},
   "source": [
    "### Dataset Overview\n",
    "\n",
    "The dataset includes columns such as `student_id`, `name`, `gender`, `age`, `subject`, `exam_score`, and `exam_date`.\n",
    "\n",
    "- The `.info()` summary confirms that all columns were loaded correctly.  \n",
    "- `.describe()` shows that `age` and `exam_score` have realistic ranges, suggesting valid data values.  \n",
    "- No obvious structural issues are observed at this stage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1fbc07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "student_id     0\n",
       "name           0\n",
       "gender         0\n",
       "age            0\n",
       "subject        0\n",
       "exam_score     0\n",
       "exam_date      0\n",
       "region         0\n",
       "grade_level    0\n",
       "school         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data quality checks\n",
    "raw.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5920622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9abb0c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "student_id       int64\n",
       "name            object\n",
       "gender          object\n",
       "age              int64\n",
       "subject         object\n",
       "exam_score     float64\n",
       "exam_date       object\n",
       "region          object\n",
       "grade_level     object\n",
       "school          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6420b09c",
   "metadata": {},
   "source": [
    "## Data Quality Assessment\n",
    "After performing a comprehensive inspection of the dataset, the following observations were made:\n",
    "\n",
    "1. exam_date column stored as 'object' type\n",
    "   - It should be converted to 'datetime' format for accurate time-based analysis\n",
    "\n",
    "2. No missing values were detected in any of the 10 columns\n",
    "\n",
    "3. No duplicate records exist in the dataset, confirming data uniqueness.\n",
    "\n",
    "4.  All data types are appropriate:\n",
    "   - Numeric fields ('student_id', 'age', 'exam_score') are stored as integers or floats.\n",
    "   - Categorical fields ('gender', 'subject', 'region', 'grade_level', 'school') are stored as 'object'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2188bdba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9000, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge datasets\n",
    "full = pd.concat([raw, inc], ignore_index=True)\n",
    "full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474090ea",
   "metadata": {},
   "source": [
    "### Dataset Merge\n",
    "\n",
    "The raw and incremental datasets were combined into a single DataFrame for validation.  \n",
    "This merge ensures that all new student records are appended to the main dataset.  \n",
    "\n",
    "After merging:\n",
    "- The combined dataset contains approximately **9,000 rows**.\n",
    "- No structural inconsistencies were detected between the two sources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f0baa32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9000, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save validated data\n",
    "full = pd.concat([raw, inc], ignore_index=True)\n",
    "full.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03b350e",
   "metadata": {},
   "source": [
    "### Data Validation Summary\n",
    "Both raw and incremental datasets were successfully merged and inspected.  \n",
    "The resulting validated datasets have been saved to the `/data` folder as:\n",
    "\n",
    "- `validated_full.csv`\n",
    "- `validated_incremental.csv`\n",
    "\n",
    "These files maintain the original structure but have been confirmed to be free of missing or duplicate records.  \n",
    "The next notebook (`etl_transform.ipynb`) will perform cleaning and data type conversions such as converting `exam_date` to datetime.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6db68666",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save validated data\n",
    "full.to_csv('data/validated_data.csv', index=False)\n",
    "inc.to_csv('data/validated_incremental_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99eceab",
   "metadata": {},
   "source": [
    "### Saving Validated Data\n",
    "\n",
    "The validated datasets were exported to the `/data` folder as:\n",
    "\n",
    "- `validated_full.csv`\n",
    "- `validated_incremental.csv`\n",
    "\n",
    "These files preserve the original data but confirm that the structure and record integrity are intact.  \n",
    "They will serve as the clean input for the **Transform** phase, where further cleaning, standardization, and enrichment will occur.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d239b5",
   "metadata": {},
   "source": [
    "## ✅ Extract Phase Summary\n",
    "\n",
    "| Step | Description | Status |\n",
    "|------|--------------|--------|\n",
    "| Data Loading | Imported raw and incremental datasets | ✅ |\n",
    "| Data Inspection | Checked structure and summary stats | ✅ |\n",
    "| Data Quality | No missing or duplicate records found | ✅ |\n",
    "| Data Validation | Confirmed consistent schema | ✅ |\n",
    "| Data Merge | Combined datasets into a validated version | ✅ |\n",
    "| File Export | Saved validated CSV files to `/data` | ✅ |\n",
    "\n",
    "The Extract phase has been successfully completed.  \n",
    "The next notebook (`etl_transform.ipynb`) will handle cleaning, formatting, and feature transformation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
