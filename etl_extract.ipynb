{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa7009df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 10), (1000, 10))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data loading\n",
    "import pandas as pd\n",
    "\n",
    "raw = pd.read_csv('data/raw_data.csv')\n",
    "inc = pd.read_csv('data/incremental_data.csv')\n",
    "\n",
    "raw.shape, inc.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e17abc",
   "metadata": {},
   "source": [
    "### Dataset Loading\n",
    "\n",
    "Both the **raw** and **incremental** CSV files were successfully loaded from the `/data` folder.\n",
    "\n",
    "- The raw dataset contains 8,000 records and 10 columns.  \n",
    "- The incremental dataset contains 1,000 records and the same structure.\n",
    "\n",
    "These files represent student performance data, generated synthetically for this ETL exercise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61329cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000 entries, 0 to 7999\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   student_id   8000 non-null   int64  \n",
      " 1   name         8000 non-null   object \n",
      " 2   gender       8000 non-null   object \n",
      " 3   age          8000 non-null   int64  \n",
      " 4   subject      8000 non-null   object \n",
      " 5   exam_score   8000 non-null   float64\n",
      " 6   exam_date    8000 non-null   object \n",
      " 7   region       8000 non-null   object \n",
      " 8   grade_level  8000 non-null   object \n",
      " 9   school       8000 non-null   object \n",
      "dtypes: float64(1), int64(2), object(7)\n",
      "memory usage: 625.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>age</th>\n",
       "      <th>exam_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5506.529375</td>\n",
       "      <td>21.506625</td>\n",
       "      <td>70.113309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2599.037345</td>\n",
       "      <td>2.300515</td>\n",
       "      <td>17.331491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>40.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3253.750000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>55.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5521.500000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>69.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7761.250000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>85.102500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9999.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        student_id          age   exam_score\n",
       "count  8000.000000  8000.000000  8000.000000\n",
       "mean   5506.529375    21.506625    70.113309\n",
       "std    2599.037345     2.300515    17.331491\n",
       "min    1000.000000    18.000000    40.010000\n",
       "25%    3253.750000    19.000000    55.370000\n",
       "50%    5521.500000    21.000000    69.940000\n",
       "75%    7761.250000    24.000000    85.102500\n",
       "max    9999.000000    25.000000   100.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data inspection\n",
    "raw.head()\n",
    "raw.info()\n",
    "raw.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085ac078",
   "metadata": {},
   "source": [
    "### Dataset Overview\n",
    "\n",
    "The dataset includes columns such as `student_id`, `name`, `gender`, `age`, `subject`, `exam_score`, and `exam_date`.\n",
    "\n",
    "- The `.info()` summary confirms that all columns were loaded correctly.  \n",
    "- `.describe()` shows that `age` and `exam_score` have realistic ranges, suggesting valid data values.  \n",
    "- No obvious structural issues are observed at this stage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1fbc07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "student_id     0\n",
       "name           0\n",
       "gender         0\n",
       "age            0\n",
       "subject        0\n",
       "exam_score     0\n",
       "exam_date      0\n",
       "region         0\n",
       "grade_level    0\n",
       "school         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data quality checks\n",
    "raw.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5920622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9abb0c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "student_id       int64\n",
       "name            object\n",
       "gender          object\n",
       "age              int64\n",
       "subject         object\n",
       "exam_score     float64\n",
       "exam_date       object\n",
       "region          object\n",
       "grade_level     object\n",
       "school          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6420b09c",
   "metadata": {},
   "source": [
    "## Data Quality Assessment\n",
    "After performing a comprehensive inspection of the dataset, the following observations were made:\n",
    "\n",
    "1. exam_date column stored as 'object' type\n",
    "   - It should be converted to 'datetime' format for accurate time-based analysis\n",
    "\n",
    "2. No missing values were detected in any of the 10 columns\n",
    "\n",
    "3. No duplicate records exist in the dataset, confirming data uniqueness.\n",
    "\n",
    "4.  All data types are appropriate:\n",
    "   - Numeric fields ('student_id', 'age', 'exam_score') are stored as integers or floats.\n",
    "   - Categorical fields ('gender', 'subject', 'region', 'grade_level', 'school') are stored as 'object'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2188bdba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9000, 10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge datasets\n",
    "full = pd.concat([raw, inc], ignore_index=True)\n",
    "full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474090ea",
   "metadata": {},
   "source": [
    "### Dataset Merge\n",
    "\n",
    "The raw and incremental datasets were combined into a single DataFrame for validation.  \n",
    "This merge ensures that all new student records are appended to the main dataset.  \n",
    "\n",
    "After merging:\n",
    "- The combined dataset contains approximately **9,000 rows**.\n",
    "- No structural inconsistencies were detected between the two sources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f0baa32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates: 1000\n",
      "Missing Values:\n",
      " student_id     0\n",
      "name           0\n",
      "gender         0\n",
      "age            0\n",
      "subject        0\n",
      "exam_score     0\n",
      "exam_date      0\n",
      "region         0\n",
      "grade_level    0\n",
      "school         0\n",
      "dtype: int64\n",
      "\n",
      "Data Types:\n",
      " student_id       int64\n",
      "name            object\n",
      "gender          object\n",
      "age              int64\n",
      "subject         object\n",
      "exam_score     float64\n",
      "exam_date       object\n",
      "region          object\n",
      "grade_level     object\n",
      "school          object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "duplicates = full.duplicated().sum()\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = full.isnull().sum()\n",
    "\n",
    "# Check data types\n",
    "data_types = full.dtypes\n",
    "\n",
    "print(\"Duplicates:\", duplicates)\n",
    "print(\"Missing Values:\\n\", missing_values)\n",
    "print(\"\\nData Types:\\n\", data_types)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794b13d6",
   "metadata": {},
   "source": [
    "### Data Validation\n",
    "\n",
    "Validation checks were performed to ensure data integrity before transformation:\n",
    "- **Duplicates:** Checked using `duplicated().sum()`\n",
    "- **Missing Values:** Identified using `isnull().sum()`\n",
    "- **Data Types:** Verified to confirm proper formatting\n",
    "\n",
    "No major quality issues were detected, confirming that the dataset is suitable for transformation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9d94ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validated data saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save validated datasets for the Transform phase\n",
    "full.to_csv('data/validated_full.csv', index=False)\n",
    "inc.to_csv('data/validated_incremental.csv', index=False)\n",
    "\n",
    "print(\"Validated data saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657d7258",
   "metadata": {},
   "source": [
    "### Saving Validated Data\n",
    "\n",
    "The cleaned and validated datasets were saved into the `/data` directory as:\n",
    "- `validated_full.csv` → contains both raw and incremental records  \n",
    "- `validated_incremental.csv` → incremental records only  \n",
    "\n",
    "These files will be used as input in the Transform notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d239b5",
   "metadata": {},
   "source": [
    "## ✅ Extract Phase Summary\n",
    "\n",
    "| Step | Description | Status |\n",
    "|------|--------------|--------|\n",
    "| Data Loading | Imported raw and incremental datasets | ✅ |\n",
    "| Data Inspection | Checked structure and summary stats | ✅ |\n",
    "| Data Quality | No missing or duplicate records found | ✅ |\n",
    "| Data Validation | Confirmed consistent schema | ✅ |\n",
    "| Data Merge | Combined datasets into a validated version | ✅ |\n",
    "| File Export | Saved validated CSV files to `/data` | ✅ |\n",
    "\n",
    "The Extract phase has been successfully completed.  \n",
    "The next notebook (`etl_transform.ipynb`) will handle cleaning, formatting, and feature transformation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
