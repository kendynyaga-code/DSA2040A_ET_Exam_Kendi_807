{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c9e92c9",
   "metadata": {},
   "source": [
    "# ETL Transform Phase\n",
    "\n",
    "### Objective\n",
    "This notebook performs the **Transform** phase of the ETL process.  \n",
    "Here, the validated datasets from the Extract phase are cleaned, standardized, and enriched to ensure data quality and usability.\n",
    "\n",
    "Key operations include:\n",
    "- Handling missing values  \n",
    "- Standardizing formats and cases  \n",
    "- Converting data types  \n",
    "- Creating derived columns  \n",
    "- Filtering and categorizing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a447cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9000, 10), (1000, 10))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Load existing validated datasets\n",
    "data_dir = Path('data')\n",
    "validated_full = data_dir / 'validated_full.csv'\n",
    "validated_inc = data_dir / 'validated_incremental.csv'\n",
    "\n",
    "if validated_full.exists() and validated_inc.exists():\n",
    "    full = pd.read_csv(validated_full)\n",
    "    inc = pd.read_csv(validated_inc)\n",
    "else:\n",
    "    # fallback: use raw and incremental, then combine\n",
    "    raw = pd.read_csv(data_dir / 'raw_data.csv')\n",
    "    inc = pd.read_csv(data_dir / 'incremental_data.csv')\n",
    "    full = pd.concat([raw, inc], ignore_index=True)\n",
    "    full.to_csv(data_dir / 'validated_full.csv', index=False)\n",
    "    inc.to_csv(data_dir / 'validated_incremental.csv', index=False)\n",
    "\n",
    "full.shape, inc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d5cd89",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "\n",
    "The validated datasets were loaded from the `/data` folder.  \n",
    "If they were not found, the raw and incremental data were revalidated and merged to ensure continuity.\n",
    "\n",
    "This step ensures that the Transform phase always begins with a consistent and verified dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ad4df78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nyaga\\AppData\\Local\\Temp\\ipykernel_13820\\1961318393.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  full[col].fillna('Unknown', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Check missing values\n",
    "full.isnull().sum()\n",
    "\n",
    "# Fill missing text columns with \"Unknown\"\n",
    "for col in ['region', 'school']:\n",
    "    if col in full.columns:\n",
    "        full[col].fillna('Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781b3191",
   "metadata": {},
   "source": [
    "### Transformation 1 – Handle Missing Values\n",
    "\n",
    "Missing entries in the `region` and `school` columns (if any) were filled with `\"Unknown\"`.  \n",
    "This prevents null-related issues during aggregation or analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc6b1a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize casing for selected columns\n",
    "text_cols = ['gender', 'region', 'subject', 'grade_level']\n",
    "for col in text_cols:\n",
    "    if col in full.columns:\n",
    "        full[col] = full[col].str.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5574b9c",
   "metadata": {},
   "source": [
    "### Transformation 2 – Standardize Text Casing\n",
    "\n",
    "Categorical fields such as `gender`, `region`, and `subject` were standardized to title case (e.g., \"Male\", \"Female\").  \n",
    "This ensures uniform text representation across the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "493c447d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2025-07-02\n",
       "1   2025-09-09\n",
       "2   2025-05-10\n",
       "3   2025-08-12\n",
       "4   2024-10-21\n",
       "Name: exam_date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full['exam_date'] = pd.to_datetime(full['exam_date'], errors='coerce')\n",
    "full['exam_date'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338c491b",
   "metadata": {},
   "source": [
    "### Transformation 3 – Convert `exam_date` to Datetime\n",
    "\n",
    "The `exam_date` column was originally stored as a string (`object`).  \n",
    "It has been converted into a proper `datetime` data type to allow for accurate time-based filtering and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59fa0ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exam_score</th>\n",
       "      <th>score_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.23</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71.79</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.66</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56.96</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68.71</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   exam_score score_status\n",
       "0       48.23         Fail\n",
       "1       71.79         Pass\n",
       "2       41.66         Fail\n",
       "3       56.96         Pass\n",
       "4       68.71         Pass"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full['score_status'] = full['exam_score'].apply(lambda x: 'Pass' if x >= 50 else 'Fail')\n",
    "full[['exam_score', 'score_status']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2878154",
   "metadata": {},
   "source": [
    "### Transformation 4 – Create Derived Column\n",
    "\n",
    "A new column named `score_status` was added to indicate whether a student passed or failed:\n",
    "- **Pass:** score ≥ 50  \n",
    "- **Fail:** score < 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d41f7fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exam_score</th>\n",
       "      <th>performance_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.23</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71.79</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.66</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56.96</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68.71</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   exam_score performance_level\n",
       "0       48.23               Low\n",
       "1       71.79              Good\n",
       "2       41.66               Low\n",
       "3       56.96           Average\n",
       "4       68.71           Average"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins = [0, 50, 70, 85, 100]\n",
    "labels = ['Low', 'Average', 'Good', 'Excellent']\n",
    "full['performance_level'] = pd.cut(full['exam_score'], bins=bins, labels=labels, include_lowest=True)\n",
    "full[['exam_score', 'performance_level']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbab147",
   "metadata": {},
   "source": [
    "### Transformation 5 – Categorize Scores\n",
    "\n",
    "Students were grouped into performance levels based on their exam scores:\n",
    "- **Low:** 0–50  \n",
    "- **Average:** 50–70  \n",
    "- **Good:** 70–85  \n",
    "- **Excellent:** 85–100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55f89f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'name' in full.columns:\n",
    "    full.drop(columns=['name'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be38ee57",
   "metadata": {},
   "source": [
    "### Transformation 6 – Drop Irrelevant Columns \n",
    "\n",
    "The `name` column was removed since it is not necessary for analysis and may raise privacy concerns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d947591c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path('transformed').mkdir(exist_ok=True)\n",
    "full.to_csv('transformed/transformed_full.csv', index=False)\n",
    "inc.to_csv('transformed/transformed_incremental.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719a14a4",
   "metadata": {},
   "source": [
    "### Saving Transformed Data\n",
    "\n",
    "Both transformed datasets were exported into the `/transformed` folder as:\n",
    "- `transformed_full.csv`\n",
    "- `transformed_incremental.csv`\n",
    "\n",
    "They are now cleaned, standardized, and enriched for analysis or loading into a warehouse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6185ec",
   "metadata": {},
   "source": [
    "## ✅ Transform Phase Summary\n",
    "\n",
    "| Category | Transformation | Result |\n",
    "|-----------|----------------|--------|\n",
    "| Cleaning | Filled missing values | ✅ |\n",
    "| Standardization | Standardized text case | ✅ |\n",
    "| Structural | Converted `exam_date` to datetime | ✅ |\n",
    "| Enrichment | Added `score_status` | ✅ |\n",
    "| Categorization | Created performance levels | ✅ |\n",
    "| (Optional) | Dropped name column | ✅ |\n",
    "\n",
    "The Transform phase successfully cleaned and enhanced the validated data, producing two ready-to-use CSV files for the next ETL step or reporting.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
